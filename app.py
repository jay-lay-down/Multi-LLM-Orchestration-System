import os
import time

import anthropic
import google.generativeai as genai
import openai
from dotenv import load_dotenv

# =========================================================
# [ì„¤ì •] API í‚¤ ì…ë ¥ (ë°˜ë“œì‹œ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ì„¸ìš”!)
# =========================================================
load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
CLAUDE_API_KEY = os.getenv("CLAUDE_API_KEY")

if not (OPENAI_API_KEY and GEMINI_API_KEY and CLAUDE_API_KEY):
    missing = [
        name for name, value in (
            ("OPENAI_API_KEY", OPENAI_API_KEY),
            ("GEMINI_API_KEY", GEMINI_API_KEY),
            ("CLAUDE_API_KEY", CLAUDE_API_KEY),
        )
        if not value
    ]
    raise EnvironmentError(
        "í•„ìˆ˜ API í‚¤ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. .env í˜¹ì€ í™˜ê²½ë³€ìˆ˜ì— ë‹¤ìŒ í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”: "
        + ", ".join(missing)
    )

# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì´ˆê¸°í™”
openai_client = openai.OpenAI(api_key=OPENAI_API_KEY)
anthropic_client = anthropic.Anthropic(api_key=CLAUDE_API_KEY)
genai.configure(api_key=GEMINI_API_KEY)

# =========================================================
# 1. í•˜ì´ë¸Œë¦¬ë“œ ì—ì´ì „íŠ¸ í´ë˜ìŠ¤ (3ì‚¬ í†µí•©)
# =========================================================
class MultiModelAgent:
    def __init__(self, name, provider, model_name, role_desc, style_desc):
        self.name = name
        self.provider = provider  # "openai", "google", "anthropic"
        self.model_name = model_name
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        self.system_prompt = f"""
        [Role]: {name}
        [Description]: {role_desc}
        [Style]: {style_desc}
        
        ì§€ê¸ˆ ìš°ë¦¬ëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ ì¢Œë‹´íšŒ ì¤‘ì…ë‹ˆë‹¤. 
        ëŒ€í™” íë¦„ì„ íŒŒì•…í•˜ê³  ë‹¹ì‹ ì˜ ì—­í• ì— ë§ì¶° 3ë¬¸ì¥ ì´ë‚´ë¡œ ë‚ ì¹´ë¡­ê²Œ ë°œì–¸í•˜ì„¸ìš”.
        """

    def speak(self, history_log):
        """
        history_log: ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™” ë‚´ìš© (List of dicts or String)
        """
        print(f"ğŸ¤– {self.name} ({self.model_name}) ìƒê° ì¤‘...")
        
        try:
            # -------------------------------------------------
            # CASE 1: OpenAI 
            # -------------------------------------------------
            if self.provider == "openai":
                messages = [{"role": "system", "content": self.system_prompt}]
                # ê¸°ë¡ëœ ëŒ€í™” ë‚´ìš©ì„ User ë©”ì‹œì§€ë¡œ ì••ì¶•í•´ì„œ ì „ë‹¬
                messages.append({"role": "user", "content": f"ëŒ€í™” ê¸°ë¡:\n{history_log}"})
                
                response = openai_client.chat.completions.create(
                    model=self.model_name,
                    messages=messages,
                    temperature=0.7
                )
                return response.choices[0].message.content

            # -------------------------------------------------
            # CASE 2: Anthropic 
            # -------------------------------------------------
            elif self.provider == "anthropic":
                # í´ë¡œë“œëŠ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ê°€ íŒŒë¼ë¯¸í„°ë¡œ ë”°ë¡œ ë¹ ì§
                response = anthropic_client.messages.create(
                    model=self.model_name,
                    max_tokens=1024,
                    system=self.system_prompt,
                    messages=[
                        {"role": "user", "content": f"ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™” íë¦„ì„ ë³´ê³  ë‹µë³€í•˜ì„¸ìš”:\n{history_log}"}
                    ]
                )
                return response.content[0].text

            # -------------------------------------------------
            # CASE 3: Gemini
            # -------------------------------------------------
            elif self.provider == "google":
                model = genai.GenerativeModel(self.model_name)
                # ì œë¯¸ë‚˜ì´ëŠ” í”„ë¡¬í”„íŠ¸ í•©ì³ì„œ ë³´ë‚´ëŠ” ê²Œ ì ¤ í¸í•¨
                full_prompt = f"{self.system_prompt}\n\n[í˜„ì¬ ëŒ€í™” ë¡œê·¸]\n{history_log}\n\n[ë‹¹ì‹ ì˜ ë°œì–¸]:"
                response = model.generate_content(full_prompt)
                return response.text

        except Exception as e:
            return f"âŒ [Error] {self.provider} í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}"

# =========================================================
# 2. ì–´ë²¤ì ¸ìŠ¤ íŒ€ êµ¬ì„± (í˜ë¥´ì†Œë‚˜)
# =========================================================
statistician = MultiModelAgent(
    name="Statistician",
    provider="openai",
    model_name="gpt-4o-mini",
    role_desc="í†µê³„í•™ì / ë°ì´í„° ë¶„ì„ê°€ë¡œì„œ ê°ê´€ì  ê·¼ê±°ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.",
    style_desc="ê°„ê²°í•˜ê³  ë¶„ì„ì ì¸ í†¤ìœ¼ë¡œ 3ë¬¸ì¥ ì´ë‚´ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.",
)

client = MultiModelAgent(
    name="Client",
    provider="anthropic",
    model_name="claude-3-5-sonnet-20240620",
    role_desc="í”„ë¡œë•íŠ¸ì˜ í´ë¼ì´ì–¸íŠ¸ì´ì ìµœì¢… ì˜ì‚¬ê²°ì •ê¶Œìì…ë‹ˆë‹¤. ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ì™€ ë¦¬ìŠ¤í¬ì— ì˜ˆë¯¼í•©ë‹ˆë‹¤.",
    style_desc="í˜„ì‹¤ì ì´ê³  ì§ì„¤ì ì¸ ì§ˆë¬¸ì„ ë˜ì§€ë˜, ê°ì •ì ì¸ ë°˜ì‘ì„ ì‚´ì§ ë‹´ì•„ëƒ…ë‹ˆë‹¤.",
)

pm = MultiModelAgent(
    name="Project Manager",
    provider="google",
    model_name="gemini-1.5-pro",
    role_desc="í”„ë¡œì íŠ¸ ë§¤ë‹ˆì €ë¡œì„œ ë‘ ê´€ì ì„ ì¡°ìœ¨í•˜ê³  ì‹¤í–‰ í”Œëœì„ ì œì•ˆí•©ë‹ˆë‹¤.",
    style_desc="ì¤‘ì¬ì ì—­í• ë¡œ, êµ¬ì²´ì ì¸ ì•¡ì…˜ ì•„ì´í…œì„ ì œì•ˆí•©ë‹ˆë‹¤.",
)

# =========================================================
# 3. ì¢Œë‹´íšŒ ì‹¤í–‰ ë£¨í”„
# =========================================================
def run_debate(topic):
    history_text = f"ì£¼ì œ: {topic}\n"
    print(f"ğŸ”¥ [AI ì¢Œë‹´íšŒ ì‹œì‘] ì£¼ì œ: {topic}\n")
    print("="*60)

    # ë°œì–¸ ìˆœì„œ: í´ë¼ì´ì–¸íŠ¸(ë¶ˆí‰) -> í†µê³„í•™ì(ë°˜ë°•) -> PM(ì¤‘ì¬) -> í´ë¼ì´ì–¸íŠ¸(ì¬ë°˜ë°•)...
    speakers = [client, statistician, pm, client, pm]

    for speaker in speakers:
        # 1. ë§í•˜ê¸°
        msg = speaker.speak(history_text)
        
        # 2. ì¶œë ¥
        print(f"\n[{speaker.name}]:\n{msg}")
        print("-" * 60)
        
        # 3. ê¸°ë¡ (ë‹¤ìŒ íƒ€ìê°€ ì½ì„ ìˆ˜ ìˆê²Œ ëˆ„ì )
        history_text += f"\n[{speaker.name}]: {msg}"
        
        # 4. ë”œë ˆì´ (ì‚¬ëŒì´ ì½ì„ ì‹œê°„)
        time.sleep(1.5)

if __name__ == "__main__":
    run_debate("ìš°ë¦¬ íšŒì‚¬ ì‹ ì œí’ˆì— 'AI ì±—ë´‡' ê¸°ëŠ¥ì„ ë„£ì–´ì•¼ í• ê¹Œ?")
